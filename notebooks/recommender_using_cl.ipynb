{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This is an implementation of a Furniture Recommender for an area in a selected place in a room using Contrastive Learning. CL is a powerful form of machine learning that teaches a model to differentiate between similar and dissimilar data points by contrasting them against each other. This form of machine learning is ideal for this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveFurnEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder for room description\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.text_projector = nn.Sequential(\n",
    "            nn.Linear(in_features=768, out_features=512), # 768 since it relates to BERT's output\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.area_encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=10, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.furniture_encoder = nn.Sequential(\n",
    "            nn.Linear(10, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def encode_room(self, text_id, text_mask, area_features):\n",
    "\n",
    "        bert_output = self.bert(input_ids=text_id, attention_mask=text_mask)\n",
    "        text_features = self.text_projector(bert_output.pooler_output)\n",
    "\n",
    "        area_features = self.area_encoder(area_features)\n",
    "\n",
    "        room_embedding = text_features + area_features\n",
    "        return torch.nn.functional.normalize(room_embedding, dim=-1)\n",
    "    \n",
    "    def encode_furniture(self, furniture_features):\n",
    "        f_embedding = self.furniture_encoder(furniture_features)\n",
    "        return torch.nn.functional.normalize(f_embedding, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function class: NTXentLoss\n",
    "\n",
    "Normalized Temperature-scaled Cross Entropy Loss is a common loss function used in Contrastive Learning. It assists in training the model to recognize similar data points and distinguish dissimilar ones, allowing it to learn without labelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, t=0.07):\n",
    "        super().__init__()\n",
    "        self.t = t\n",
    "    \n",
    "    def forward(self, room_embeddings, furniture_embeddings):\n",
    "\n",
    "        similiarity_matrix = torch.mm(room_embeddings, furniture_embeddings.t())/self.t\n",
    "\n",
    "        labels = torch.arange(similiarity_matrix.size(0)).to(similiarity_matrix.device)\n",
    "\n",
    "        loss_room = torch.nn.functional.cross_entropy(similiarity_matrix, labels)\n",
    "        loss_furniture = torch.nn.functional.cross_entropy(similiarity_matrix.t(), labels)\n",
    "\n",
    "        return (loss_room+loss_furniture)*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FurnitureRecomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, room_desc, area_feature, furniture_features, positive_pairs):\n",
    "        self.room_descriptions = room_desc\n",
    "        self.area_features = area_feature\n",
    "        self.furniture_features = furniture_features\n",
    "        self.positive_pairs = positive_pairs\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        room_index, furniture_index = self.positive_pairs[index]\n",
    "        room_desc = self.room_descriptions[room_index]\n",
    "\n",
    "        encoded = self.tokenizer(room_desc, padding=True, truncation=True, return_tensor = \"pt\")\n",
    "\n",
    "        text_ids = encoded['input_ids'].squeeze(0)\n",
    "        text_mask = encoded['attention_mask'].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            'text_ids':text_ids,\n",
    "            'text_mask':text_mask,\n",
    "            'room_desc': self.room_descriptions[room_index],\n",
    "            'area_features': self.area_features[room_index],\n",
    "            'furniture_features': self.furniture_features[furniture_index]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.positive_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ContrastiveFurnEncoder().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive_model(model, train_loader, num_epochs, device):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    criterion = NTXentLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            text_ids = batch['text_ids'].to(device)\n",
    "            text_mask = batch['text_mask'].to(device)\n",
    "            area_features = batch['area_features'].to(device)\n",
    "            furniture_features = batch['furniture_features'].to(device)\n",
    "            \n",
    "            \n",
    "            room_embeddings = model.encode_room(text_ids, text_mask, area_features)\n",
    "            furniture_embeddings = model.encode_furniture(furniture_features)\n",
    "            \n",
    "            \n",
    "            loss = criterion(room_embeddings, furniture_embeddings)\n",
    "            total_loss+=loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
